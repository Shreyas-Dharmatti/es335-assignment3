{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T20:51:41.069667Z","iopub.status.busy":"2024-10-28T20:51:41.069280Z","iopub.status.idle":"2024-10-28T20:51:46.902846Z","shell.execute_reply":"2024-10-28T20:51:46.901913Z","shell.execute_reply.started":"2024-10-28T20:51:41.069630Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","<> <> <> <> <> <> <> <> <> <> ---> well\n","<> <> <> <> <> <> <> <> <> well ---> prince\n","<> <> <> <> <> <> <> <> well prince ---> so\n","<> <> <> <> <> <> <> well prince so ---> genoa\n","<> <> <> <> <> <> well prince so genoa ---> and\n","<> <> <> <> <> well prince so genoa and ---> lucca\n","<> <> <> <> well prince so genoa and lucca ---> are\n","<> <> <> well prince so genoa and lucca are ---> now\n","<> <> well prince so genoa and lucca are now ---> just\n","<> well prince so genoa and lucca are now just ---> family\n","well prince so genoa and lucca are now just family ---> estates\n","prince so genoa and lucca are now just family estates ---> of\n","so genoa and lucca are now just family estates of ---> the\n","genoa and lucca are now just family estates of the ---> buonapartes\n","and lucca are now just family estates of the buonapartes ---> .\n","lucca are now just family estates of the buonapartes . ---> but\n","are now just family estates of the buonapartes . but ---> i\n","now just family estates of the buonapartes . but i ---> warn\n","just family estates of the buonapartes . but i warn ---> you\n","family estates of the buonapartes . but i warn you ---> if\n","estates of the buonapartes . but i warn you if ---> you\n","of the buonapartes . but i warn you if you ---> dont\n","the buonapartes . but i warn you if you dont ---> tell\n","buonapartes . but i warn you if you dont tell ---> me\n",". but i warn you if you dont tell me ---> that\n","but i warn you if you dont tell me that ---> this\n","i warn you if you dont tell me that this ---> means\n","warn you if you dont tell me that this means ---> war\n","you if you dont tell me that this means war ---> if\n","if you dont tell me that this means war if ---> you\n","you dont tell me that this means war if you ---> still\n","dont tell me that this means war if you still ---> try\n","tell me that this means war if you still try ---> to\n","me that this means war if you still try to ---> defend\n","that this means war if you still try to defend ---> the\n","this means war if you still try to defend the ---> infamies\n","means war if you still try to defend the infamies ---> and\n","war if you still try to defend the infamies and ---> horrors\n","if you still try to defend the infamies and horrors ---> perpetrated\n","you still try to defend the infamies and horrors perpetrated ---> by\n","still try to defend the infamies and horrors perpetrated by ---> that\n","try to defend the infamies and horrors perpetrated by that ---> antichristi\n","to defend the infamies and horrors perpetrated by that antichristi ---> really\n","defend the infamies and horrors perpetrated by that antichristi really ---> believe\n","the infamies and horrors perpetrated by that antichristi really believe ---> he\n","infamies and horrors perpetrated by that antichristi really believe he ---> is\n","and horrors perpetrated by that antichristi really believe he is ---> antichristi\n","horrors perpetrated by that antichristi really believe he is antichristi ---> will\n","perpetrated by that antichristi really believe he is antichristi will ---> have\n","by that antichristi really believe he is antichristi will have ---> nothing\n","that antichristi really believe he is antichristi will have nothing ---> more\n","antichristi really believe he is antichristi will have nothing more ---> to\n","really believe he is antichristi will have nothing more to ---> do\n","believe he is antichristi will have nothing more to do ---> with\n","he is antichristi will have nothing more to do with ---> you\n","is antichristi will have nothing more to do with you ---> and\n","antichristi will have nothing more to do with you and ---> you\n","will have nothing more to do with you and you ---> are\n","have nothing more to do with you and you are ---> no\n","nothing more to do with you and you are no ---> longer\n","more to do with you and you are no longer ---> my\n","to do with you and you are no longer my ---> friend\n","do with you and you are no longer my friend ---> no\n","with you and you are no longer my friend no ---> longer\n","you and you are no longer my friend no longer ---> my\n","and you are no longer my friend no longer my ---> faithful\n","you are no longer my friend no longer my faithful ---> slave\n","are no longer my friend no longer my faithful slave ---> as\n","no longer my friend no longer my faithful slave as ---> you\n","longer my friend no longer my faithful slave as you ---> call\n","my friend no longer my faithful slave as you call ---> yourself\n","friend no longer my faithful slave as you call yourself ---> but\n","no longer my faithful slave as you call yourself but ---> how\n","longer my faithful slave as you call yourself but how ---> do\n","my faithful slave as you call yourself but how do ---> you\n","faithful slave as you call yourself but how do you ---> do\n","slave as you call yourself but how do you do ---> i\n","as you call yourself but how do you do i ---> see\n","you call yourself but how do you do i see ---> i\n","call yourself but how do you do i see i ---> have\n","yourself but how do you do i see i have ---> frightened\n","but how do you do i see i have frightened ---> yousit\n","how do you do i see i have frightened yousit ---> down\n","do you do i see i have frightened yousit down ---> and\n","you do i see i have frightened yousit down and ---> tell\n","do i see i have frightened yousit down and tell ---> me\n","i see i have frightened yousit down and tell me ---> all\n","see i have frightened yousit down and tell me all ---> the\n","i have frightened yousit down and tell me all the ---> news\n","have frightened yousit down and tell me all the news ---> .\n","<> <> <> <> <> <> <> <> <> <> ---> it\n","<> <> <> <> <> <> <> <> <> it ---> was\n","<> <> <> <> <> <> <> <> it was ---> in\n","<> <> <> <> <> <> <> it was in ---> july\n","<> <> <> <> <> <> it was in july ---> 1805\n","<> <> <> <> <> it was in july 1805 ---> and\n","<> <> <> <> it was in july 1805 and ---> the\n","<> <> <> it was in july 1805 and the ---> speaker\n","<> <> it was in july 1805 and the speaker ---> was\n","<> it was in july 1805 and the speaker was ---> the\n","it was in july 1805 and the speaker was the ---> wellknown\n","was in july 1805 and the speaker was the wellknown ---> anna\n","in july 1805 and the speaker was the wellknown anna ---> pavlovna\n","july 1805 and the speaker was the wellknown anna pavlovna ---> scherer\n","1805 and the speaker was the wellknown anna pavlovna scherer ---> maid\n","and the speaker was the wellknown anna pavlovna scherer maid ---> of\n","the speaker was the wellknown anna pavlovna scherer maid of ---> honor\n","speaker was the wellknown anna pavlovna scherer maid of honor ---> and\n","was the wellknown anna pavlovna scherer maid of honor and ---> favorite\n","the wellknown anna pavlovna scherer maid of honor and favorite ---> of\n","wellknown anna pavlovna scherer maid of honor and favorite of ---> the\n","anna pavlovna scherer maid of honor and favorite of the ---> empress\n","pavlovna scherer maid of honor and favorite of the empress ---> marya\n","scherer maid of honor and favorite of the empress marya ---> fedorovna\n","maid of honor and favorite of the empress marya fedorovna ---> .\n","of honor and favorite of the empress marya fedorovna . ---> with\n","honor and favorite of the empress marya fedorovna . with ---> these\n","and favorite of the empress marya fedorovna . with these ---> words\n","favorite of the empress marya fedorovna . with these words ---> she\n","of the empress marya fedorovna . with these words she ---> greeted\n","the empress marya fedorovna . with these words she greeted ---> prince\n","empress marya fedorovna . with these words she greeted prince ---> vasili\n","marya fedorovna . with these words she greeted prince vasili ---> kuragin\n","fedorovna . with these words she greeted prince vasili kuragin ---> a\n",". with these words she greeted prince vasili kuragin a ---> man\n","with these words she greeted prince vasili kuragin a man ---> of\n","these words she greeted prince vasili kuragin a man of ---> high\n","words she greeted prince vasili kuragin a man of high ---> rank\n","she greeted prince vasili kuragin a man of high rank ---> and\n","greeted prince vasili kuragin a man of high rank and ---> importance\n","prince vasili kuragin a man of high rank and importance ---> who\n","vasili kuragin a man of high rank and importance who ---> was\n","kuragin a man of high rank and importance who was ---> the\n","a man of high rank and importance who was the ---> first\n","man of high rank and importance who was the first ---> to\n","of high rank and importance who was the first to ---> arrive\n","high rank and importance who was the first to arrive ---> at\n","rank and importance who was the first to arrive at ---> her\n","and importance who was the first to arrive at her ---> reception\n","importance who was the first to arrive at her reception ---> .\n","who was the first to arrive at her reception . ---> anna\n","was the first to arrive at her reception . anna ---> pavlovna\n","the first to arrive at her reception . anna pavlovna ---> had\n","first to arrive at her reception . anna pavlovna had ---> had\n","to arrive at her reception . anna pavlovna had had ---> a\n","arrive at her reception . anna pavlovna had had a ---> cough\n","at her reception . anna pavlovna had had a cough ---> for\n","her reception . anna pavlovna had had a cough for ---> some\n","reception . anna pavlovna had had a cough for some ---> days\n",". anna pavlovna had had a cough for some days ---> .\n"]}],"source":["import torch\n","import torch.nn as nn\n","import re\n","import requests\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","url = \"https://cs.stanford.edu/people/karpathy/char-rnn/warpeace_input.txt\"\n","response = requests.get(url)\n","text = response.text\n","\n","\n","text = re.sub(r'\\n\\s*\\n', ' <PARA> ', text)  # Replace paragraph breaks with `<PARA>`\n","text = \"\\n\".join(line + \" \" for line in text.splitlines())  # Add space at the end of each line\n","text = re.sub('[^a-zA-Z0-9 \\.<>]', '', text)  # Keep only alphanumeric, space, period, and tokens\n","text = text.lower().strip()\n","\n","words = re.findall(r'\\b\\w+\\b|[.]|<PARA>', text)\n","vocab = sorted(set(words + [\"<>\"]))  # Add `<>` to the vocabulary\n","stoi = {s: i for i, s in enumerate(vocab)}  # Map each token to a unique index\n","itos = {i: s for s, i in stoi.items()}      # Reverse map from index to token\n","\n","block_size =10   # Context length: how many words we use to predict the next one\n","X, Y = [], []    \n","# Start context with padding tokens\n","context = [stoi[\"<>\"]] * block_size\n","\n","for word in words + ['para']:  # Include <PARA> as end-of-sequence marker\n","    if word == \"para\":\n","        # Reset context to padding tokens on new paragraph\n","        context = [stoi[\"<>\"]] * block_size\n","    else:\n","        # Append current context to X and target word index to Y\n","        ix = stoi[word]  \n","        X.append(context)  \n","        Y.append(ix)       \n","\n","        # Update context by sliding the window to include the next word index\n","        context = context[1:] + [ix]  # Move the window without reinitializing\n","\n","\n","for i in range(150):\n","    print(' '.join(itos[idx] if idx in itos else '<>' for idx in X[i]), '--->', itos[Y[i]])\n","\n","\n","X = torch.tensor(X).to(device)\n","Y = torch.tensor(Y).to(device)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T20:51:46.904741Z","iopub.status.busy":"2024-10-28T20:51:46.904446Z","iopub.status.idle":"2024-10-28T20:51:46.910482Z","shell.execute_reply":"2024-10-28T20:51:46.909639Z","shell.execute_reply.started":"2024-10-28T20:51:46.904709Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(torch.Size([592050, 10]), torch.Size([592050]))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["X.shape, Y.shape"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T20:51:46.911840Z","iopub.status.busy":"2024-10-28T20:51:46.911567Z","iopub.status.idle":"2024-10-28T20:51:46.930804Z","shell.execute_reply":"2024-10-28T20:51:46.930066Z","shell.execute_reply.started":"2024-10-28T20:51:46.911811Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[   93,    93,    93,    93,    93,    93,    93,    93,    93,    93],\n","        [   93,    93,    93,    93,    93,    93,    93,    93,    93, 19477],\n","        [   93,    93,    93,    93,    93,    93,    93,    93, 19477, 13580],\n","        [   93,    93,    93,    93,    93,    93,    93, 19477, 13580, 16349],\n","        [   93,    93,    93,    93,    93,    93, 19477, 13580, 16349,  7494],\n","        [   93,    93,    93,    93,    93, 19477, 13580, 16349,  7494,   724],\n","        [   93,    93,    93,    93, 19477, 13580, 16349,  7494,   724, 10583],\n","        [   93,    93,    93, 19477, 13580, 16349,  7494,   724, 10583,   995],\n","        [   93,    93, 19477, 13580, 16349,  7494,   724, 10583,   995, 11958],\n","        [   93, 19477, 13580, 16349,  7494,   724, 10583,   995, 11958,  9721],\n","        [19477, 13580, 16349,  7494,   724, 10583,   995, 11958,  9721,  6500],\n","        [13580, 16349,  7494,   724, 10583,   995, 11958,  9721,  6500,  6064],\n","        [16349,  7494,   724, 10583,   995, 11958,  9721,  6500,  6064, 12119],\n","        [ 7494,   724, 10583,   995, 11958,  9721,  6500,  6064, 12119, 17645],\n","        [  724, 10583,   995, 11958,  9721,  6500,  6064, 12119, 17645,  2381]],\n","       device='cuda:0')"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["X[:15]"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T20:51:46.932234Z","iopub.status.busy":"2024-10-28T20:51:46.931946Z","iopub.status.idle":"2024-10-28T20:51:46.936613Z","shell.execute_reply":"2024-10-28T20:51:46.935759Z","shell.execute_reply.started":"2024-10-28T20:51:46.932175Z"},"trusted":true},"outputs":[],"source":["# Hyperparameters\n","block_size = 10  \n","embedding_dim = 64  \n","hidden_size = 1024  "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T20:51:46.940326Z","iopub.status.busy":"2024-10-28T20:51:46.939753Z","iopub.status.idle":"2024-10-28T20:51:46.947548Z","shell.execute_reply":"2024-10-28T20:51:46.946679Z","shell.execute_reply.started":"2024-10-28T20:51:46.940294Z"},"trusted":true},"outputs":[],"source":["class NextWord(nn.Module):\n","  def __init__(self, block_size, vocab_size, emb_dim, hidden_size):\n","    super().__init__()\n","    self.emb = nn.Embedding(vocab_size, emb_dim)\n","    self.lin1 = nn.Linear(block_size * emb_dim, hidden_size)\n","    self.lin2 = nn.Linear(hidden_size, vocab_size)\n","\n","  def forward(self, x):\n","    x = self.emb(x)\n","    x = x.view(x.shape[0], -1)\n","    x = torch.relu(self.lin1(x))\n","    x = self.lin2(x)\n","    return x"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T20:51:46.948936Z","iopub.status.busy":"2024-10-28T20:51:46.948611Z","iopub.status.idle":"2024-10-28T20:51:47.158747Z","shell.execute_reply":"2024-10-28T20:51:47.157735Z","shell.execute_reply.started":"2024-10-28T20:51:46.948905Z"},"trusted":true},"outputs":[],"source":["# Initialize model\n","vocab_size = len(stoi)\n","model = NextWord(block_size, vocab_size, embedding_dim, hidden_size).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T20:51:47.160486Z","iopub.status.busy":"2024-10-28T20:51:47.160087Z","iopub.status.idle":"2024-10-28T20:51:47.166588Z","shell.execute_reply":"2024-10-28T20:51:47.165570Z","shell.execute_reply.started":"2024-10-28T20:51:47.160444Z"},"trusted":true},"outputs":[{"data":{"text/plain":["NextWord(\n","  (emb): Embedding(20070, 64)\n","  (lin1): Linear(in_features=640, out_features=1024, bias=True)\n","  (lin2): Linear(in_features=1024, out_features=20070, bias=True)\n",")"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T20:51:47.168111Z","iopub.status.busy":"2024-10-28T20:51:47.167792Z","iopub.status.idle":"2024-10-28T20:51:47.202315Z","shell.execute_reply":"2024-10-28T20:51:47.201425Z","shell.execute_reply.started":"2024-10-28T20:51:47.168080Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated sentence: this is a sample sentence unbearable armswell gibrards acute between shawls fattened monastery sharpnosed untried comenothing mode sleigh distinguishes adapting\n"]}],"source":["def predict_next_words(model, stoi, itos, input_words, device, num_words=5):\n","\n","    model.eval()  # Set model to evaluation mode\n","    context = [stoi.get(word, 0) for word in input_words[-block_size:]]\n","    sentence = input_words.copy()\n","    \n","    for _ in range(num_words):\n","        input_seq = torch.tensor(context, dtype=torch.long).unsqueeze(0).to(device)\n","        with torch.no_grad():\n","            output = model(input_seq)\n","            _, predicted = torch.max(output, dim=1)\n","            next_word = itos[predicted.item()]\n","            sentence.append(next_word)\n","            \n","            # Update context for the next prediction\n","            context = context[1:] + [predicted.item()]\n","    \n","    return ' '.join(sentence)\n","\n","# Example usage \n","input_words = ['','','','','','','','','','','this', 'is', 'a', 'sample', 'sentence']\n","print(\"Generated sentence:\", predict_next_words(model, stoi, itos, input_words, device, num_words=15).strip())"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T20:51:47.203816Z","iopub.status.busy":"2024-10-28T20:51:47.203469Z","iopub.status.idle":"2024-10-28T22:28:18.622151Z","shell.execute_reply":"2024-10-28T22:28:18.621228Z","shell.execute_reply.started":"2024-10-28T20:51:47.203775Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","0 6.879134178161621\n","10\n","20\n","25 3.1875388622283936\n","30\n","40\n","50\n","50 2.2165377140045166\n","60\n","70\n","75 1.7624762058258057\n","80\n","90\n","100\n","100 1.4670307636260986\n","110\n","120\n","125 1.2536057233810425\n","130\n","140\n","150\n","150 1.0920164585113525\n","160\n","170\n","175 0.9635493159294128\n","180\n","190\n","200\n","200 0.858995258808136\n","210\n","220\n","225 0.7725817561149597\n","230\n","240\n","250\n","250 0.7006580233573914\n","260\n","270\n","275 0.6393033266067505\n","280\n","290\n","300\n","300 0.5871362686157227\n","310\n","320\n","325 0.541398286819458\n","330\n","340\n","350\n","350 0.5023683905601501\n","360\n","370\n","375 0.4678008556365967\n","380\n","390\n","400\n","400 0.4377448260784149\n","410\n","420\n","425 0.41048192977905273\n","430\n","440\n","450\n","450 0.385908305644989\n","460\n","470\n","475 0.36380869150161743\n","480\n","490\n","500\n","500 0.3446604311466217\n"]}],"source":["batch_size = 4096\n","print_every = 25\n","for epoch in range(501):\n","    for i in range(0, X.shape[0], batch_size):\n","        x = X[i:i+batch_size]\n","        y = Y[i:i+batch_size]\n","        y_pred = model(x)\n","        loss = loss_fn(y_pred, y)\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    if epoch % 10 ==0:\n","        print(epoch)\n","    if epoch % print_every == 0:\n","        print(epoch, loss.item())"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T22:28:18.623594Z","iopub.status.busy":"2024-10-28T22:28:18.623316Z","iopub.status.idle":"2024-10-28T22:28:18.652127Z","shell.execute_reply":"2024-10-28T22:28:18.651389Z","shell.execute_reply.started":"2024-10-28T22:28:18.623563Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated sentence: this is a sample you really . . . one thinks is over other said not in point lay out not give up to the farther questions . they had come to go to the general . youll have a soul are you in everything your honor your honor to get are to your to and others go and in\n"]}],"source":["# Example usage for trained model\n","input_words = ['','','','','','','','','','','this', 'is', 'a', 'sample', 'you']\n","print(\"Generated sentence:\", predict_next_words(model, stoi, itos, input_words, device, num_words=55).strip())"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T22:28:18.653316Z","iopub.status.busy":"2024-10-28T22:28:18.653036Z","iopub.status.idle":"2024-10-28T22:28:18.830081Z","shell.execute_reply":"2024-10-28T22:28:18.829265Z","shell.execute_reply.started":"2024-10-28T22:28:18.653286Z"},"trusted":true},"outputs":[],"source":["# Assuming the model is already trained\n","model_path = 'next_word_model_2_64_10_relu_500.pth'\n","torch.save(model.state_dict(), model_path)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T22:28:18.831587Z","iopub.status.busy":"2024-10-28T22:28:18.831281Z","iopub.status.idle":"2024-10-28T22:28:18.835829Z","shell.execute_reply":"2024-10-28T22:28:18.834854Z","shell.execute_reply.started":"2024-10-28T22:28:18.831554Z"},"trusted":true},"outputs":[],"source":["import os\n","os.chdir(r'/kaggle/working')"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-10-28T22:28:18.836958Z","iopub.status.busy":"2024-10-28T22:28:18.836709Z","iopub.status.idle":"2024-10-28T22:28:18.848354Z","shell.execute_reply":"2024-10-28T22:28:18.847607Z","shell.execute_reply.started":"2024-10-28T22:28:18.836930Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='next_word_model_2_64_10_relu_500.pth' target='_blank'>next_word_model_2_64_10_relu_500.pth</a><br>"],"text/plain":["/kaggle/working/next_word_model_2_64_10_relu_500.pth"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink\n","FileLink(r'next_word_model_2_64_10_relu_500.pth')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
